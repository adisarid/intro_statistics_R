---
title: "Analysis of Single-Factor Experiments (ANOVA)"
subtitle: ""
author: "Adi Sarid"
institute: "Tel-Aviv University"
date: "updated: `r Sys.Date()`"
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
    css: xaringan-themer.css
---

```{r setup, include=FALSE}

library(xaringanthemer)

extra_css <- list(
   ".medium" = list("font-size" = "85%",
                    "code-font-size" = "85%"),
  ".small" = list("zoom" = "70%"),
  ".extra-small" = list("font-size" = "50%",
                        "code-font-size" = "50%"),
  ".tiny" = list("font-size" = "50%",
                 "code-font-size" = "50%",
                 "zoom" = "50%"),
  ".full-width" = list(
    display = "flex",
    width   = "100%",
    flex    = "1 1 auto"
  )
)

style_mono_accent(
   header_font_google = google_font("Open Sans"),
   text_font_google   = google_font("Rubik", "300", "300i"),
   code_font_google   = google_font("Fira Mono"),
   extra_css = extra_css,
   header_h1_font_size = "2.3rem"
   
)

theme_xaringan()

options(htmltools.dir.version = FALSE, fig.width = 3, fig.height = 3)
knitr::opts_chunk$set(fig.dim=c(3, 3), fig.align = "center")
library(tidyverse)
```

# Experiment Design - Motivation

With methods of hypothesis testing, we were able to discern the differences between two groups (i.e., unpaird two-sample test).

For example trying to see if cars with 4 cylinders are more efficient than cars with 8 cylinders.

.small[
```{r mtcars compare cyls}
mtcars %>% 
   filter(cyl != 6) %>% 
   t.test(formula = mpg ~ cyl, data = .)
```
]

---

# Experiment Design - Motivation (2)

Sometimes, we have more than two levels, in which case, we would like to devise a test which will compare all levels.

--

In the case of a single variable with multiple levels, this is called *single factor experiments* (in the next lecture we will also discuss *multi factor experiments*, when there are multiple levels).

--

The process invloves:

   * Conjecture - The hypothesis that motivates the experiment
   
   * Experiment - The actual test performed to investigate the conjecture
   
   * Analysis - Statistical analysis of the collected data
   
   * Conclusions - What has been learned
   
The process is iterated: to improve the experiment (e.g., add new variables or change the methods) and learn more.

--

.small[The following material is covered in Montgomery chapter 13.]

---

# Experiment Design - Motivation (3)

We would like a statistical that would highlight the efficiency of cars as a function of the number of cylinders. 

--

A boxplot can visually illustrate what we are looking for, but we cannot yield strength or significance from it.

```{r mtcars cyl comparison}
ggplot(mtcars, aes(y = mpg, x = factor(cyl))) + 
   geom_boxplot(fill = "lightblue") + 
   theme_bw()
```

--

Question: How would you use linear regression to examine this relationship?

---

# The Completely Randomized Single-Factor Experiment

Each factor level is called a *treatment* (i.e., for different treatments administered in an experiment).

--

The experimenter randomely samples subjects (either of equally sized groups or varying sized groups).

--

We describe the observations for a **completely randomized design** by a linear statistical model:

$$Y_{ij} = \mu + \tau_i + \epsilon_{ij}, \quad i = 1,\ldots,\ j=1,\ldots n$$

The value $\mu_i=\mu+\tau_i$ is the mean value of the $i$th treatment.

--

We assume that the errors $\epsilon_{i,j}$ are normally and independently distributed $\mathcal{N}(0, \sigma^2)$.

--

Two methods to select the treatments:

   * **Fixed-effects model**: the $a$ treatments were chosen specifically.
   
   * **Random-effects model** (components of variance): the $a$ treatments were a random sample from a larger population of treatments. We would like to extend the conclusions for additional treatments.

--

For now, we are going to focus on the **fixed effects model**.

---

# The Fixed-Effects Model

The treatments $\tau_i$ are defined as deviations from the overall mean $\mu$ such that: 

$$\sum_{i=1}^a{\tau_i}=0$$

--

Define:

$$y_{i\cdot}=\sum_{j=1}^n{y_{ij}}, \quad \bar{y}_{i\cdot}=y_{i\cdot}/n$$

$$y_{\cdot\cdot} = \sum_{i=1}^a\sum_{j=1}^n{y_{ij}}, \quad \bar{y}_{\cdot\cdot}=y_{\cdot\cdot}/N, \quad N=a\cdot n$$

--

We are interested in the following test:

   * $H_0: \tau_1=\ldots=\tau_a=0$
   
   * $H_1: \exists i\ |\ \tau_i\neq0$

---

# The Sum of Squares

Again, we use the sum of squares equation: $SS_T = SS_\text{Treatments} + SS_E$:

$$\sum_{i=1}^a\sum_{j=1}^n({y_{ij} - \bar{y}_{\cdot\cdot})^2} = n\sum_{i=1}^a{(\bar{y}_{i\cdot} - \bar{y}_{\cdot\cdot})^2} + \sum_{i=1}^a\sum_{j=1}^n({y_{ij} - \bar{y}_{i\cdot})^2}$$

--

The expected value of each of the errors is given by:

$$E(SS_\text{Treatments})=(a-1)\sigma^2 + n\sum_{i=1}^a{\tau_i^2}$$

$$E(SS_E) = a(n-1)\sigma^2$$

--

The degrees of freedom of each error are: 

   * $an-1$ for $SS_T$, 
   * $a-1$ for $SS_\text{Treatments}$ 
   * $a(n-1)$ for $SS_E$
   
---

# The ANOVA Test

If the null hypothesis holds, then $\tau_1=\ldots=\tau_a=0$, and

--

$MS_\text{Treatments}=SS_\text{Treatments}/(a-1)$ is an unbiased estimator of $\sigma^2$

--

The error mean square $MS_E=SS_E/[a(n-1)]$ is also an unbiased estimator of $\sigma^2$

--

Hence the following statistic has an F-distribution

$$F_0=\frac{SS_\text{Treatments}/(a-1)}{SS_E/[a(n-1)]}=\frac{MS_\text{Treatments}}{MS_E}$$

With $a-1$ and $a(n-1)$ degrees of freedom.

--

We use an upper-tail, one-sided critical region and reject $H_0$ if $f_0>f_{\alpha, a-1, a(n-1)}$.

---

# The ANOVA Table

The corresponding ANOVA table, for a Single-Factor Experiment, with a Fixed-Effects Model:

| Source of Variation | Sum of Squares | df | Mean Squares | $F_0$ |
|----------------------|-----------------|-------|:------------:|---------------------|
| Treatments | $SS_\text{Treatments}$ | $a-1$ | $MS_\text{Treatments}$ | $\frac{MS_\text{Treatments}}{MS_E}$ |
| Error | $SS_E$ | $a(n-1)$ | $MS_E$ |  |
| Total | $SS_T$ | $an-1$ |  |  |

--

For an unbalanced experiment (each treatment has varying group size, $n_i$) we would have:

$$SS_T=\sum_{i=1}^a\sum_{j=1}^{n_i}{y_{ij}^2} - \frac{y_{\cdot\cdot}^2}{N}$$

$$SS_\text{Treatments} = \sum_{i=1}^a\frac{y_{i\cdot}^2}{n_i} - \frac{y_{\cdot\cdot}^2}{N}$$

And $SS_E = SS_T-SS_\text{Treatment}$

---

# ANOVA Example

```{r anova example in mtcars}
mtcars2 <- mtcars %>% 
   mutate(cyl_fct = factor(cyl))
mtcars_anova <- aov(formula = mpg ~ cyl_fct, data = mtcars2)
summary(mtcars_anova)
```

--

Usually, ANOVA will be followed by a multiple comparisons procedures, that will help identify which factors contribute to the variation.

--

There are many such multiple comparison tests. See [this book](http://www.ievbras.ru/ecostat/Kiril/R/Biblio_N/R_Eng/Bretz2011.pdf): Bretz F., Hothorn T., and Westfall P., Multiple Comparisons Using R, CRC Press, 2011.

---

# Dunnett's  Test

The one-sided Dunnett's test takes the minimum (or maximum depending on direction) of the $a$ pairwise $t$ tests:

$$t_i=\frac{\bar{y}_{i\cdot}-\bar{y}_0}{s\sqrt{\frac{1}{n_i} + \frac{1}{n_0}}}$$

Where $y_0$ relates to the control group (to which we are comparing the treatments), and $s^2$ is the pooled variance, i.e.:

$$s^2=\sum_{i=0}^m\sum_{j=1}^{n_j}(y_{ij}-\bar{y}_{i\cdot})^2/v$$

With $v = \sum_{i=0}^m{n_i}-(a+1)$ degrees of freedom.

--

The Dunnett's test is availble in `multcomp` like many other procedures for multiple comparisons.

---

# Dunnett's Test Example
.small[
```{r Dunnetts test example}
suppressWarnings(suppressMessages(library(multcomp)))
glht(mtcars_anova,
     linfct = mcp(cyl_fct = "Dunnett"),
     alternative = "less") %>% 
   summary()
```
]

---

# Verifying ANOVA assumptions
.small[
The ANOVA model assumes that observations are normally and independently distributed, with the same variance for each treatment. 

This can be verified using hypothesis tests on the residuals, or viewing a proper plot (e.g., qqplot). The following illustrates that some assumptions are invalid in the previous example (which?) 
]
.tiny[
```{r verifying normality, fig.dim=c(8, 3.5)}
mtcars2_resid <- mtcars2 %>% 
   mutate(resid = mtcars_anova$residuals)
boxplot_resid <- ggplot(mtcars2_resid, aes(x = cyl_fct, y = resid)) + 
   geom_boxplot(fill = "lightblue") +
   theme_bw() + ggtitle("Boxplot of residuals in each cyl level")
qqplot_resid <- ggplot(mtcars2_resid, aes(sample = (resid - mean(resid))/sd(resid))) + 
   geom_qq() + 
   theme_bw() + ggtitle("QQ plot of residuals")
cowplot::plot_grid(qqplot_resid, boxplot_resid)
```
]

---

# Determining the Sample Size

The selection of the sample size is based on the difference we want to detect, and at what test power:

$$1-\beta = P(\text{Reject } H_0 | H_1) = P(F_0>f_{1-\alpha, a-1, a(n-1)} | H_1)$$

--

The effect size represents the differences in means between groups:

$$\operatorname{ES} = \frac{\mu_\text{experiment}-\mu_\text{control}}{s}$$
.small[
```{r determining anova sample size}
pwr::pwr.anova.test(k = 3, n = NULL, f = 0.25, sig.level = 0.05, power = 0.8)
```
]

---

# The Random-Effects Model (Factor with Many Levels)

In cases the factor has a large number of levels, we cannot sample all of them. We would like to sample part of them, $a$ levels, and draw conclusions about the entire population of factor levels.

--

As before, we define

$$Y_{ij} = \mu + \tau_i + \epsilon_{ij}$$

However, this time, the factor has a variance, i.e.:

$$\operatorname{Var}(Y_{ij}) = \sigma_\tau^2 + \sigma^2$$

--

We would like to test the hypothesis that:

   * $H_0:\sigma_\tau^2=0$
   
   * $H_1:\sigma_\tau^2>0$
   
If $H_0$ holds, this means that the treatments are identical. 

--

If $\sigma_\tau^2>0$ this means that there is variability between treatments.

---

# The Random-Effects Model - Continued

The relationship of residuals still holds:

$$SS_T = SS_\text{Treatments} + SS_E$$

But the errors change:

$$E(MS_\text{Treatments}) = E\left[\frac{SS_\text{Treatments}}{a-1}\right] = \sigma^2 + n\sigma^2_\tau$$

$$E(MS_E) = E\left[\frac{SS_E}{a(n-1)}\right] = \sigma^2$$

--

Under the null hypothesis both sizes are identical and hence

$$F_0=\frac{MS_\text{Treatments}}{MS_E}$$

Is an F-distributed variable with $a-1$ and $a(n-1)$ degrees of freedom.

---

# Determining the Sample Size in the Random Effects Model

We would like to find $n$ for a given $\beta$ (type-II error) such that:

$$1-\beta = P(\text{Reject } H_0|H_1)=P(F_0>f_{\alpha, a-1, a(n-1)}|\sigma_\tau>0)$$

--

If $H_1$ is true, then the ratio $\frac{MS_\text{Treatments}/(\sigma^2+n\sigma_\tau^2)}{MS_E/\sigma^2}$ has the $F$-distribution with $a-1$ and $a(n-1)$ degrees of freedom. Then,

$$1-\beta = P\left(\frac{MS_\text{Treatements}}{MS_E}>f_{\alpha, a-1, a(n-1)}|\sigma^2_\tau>0\right) = 
P\left(\frac{MS_\text{Treatements}}{MS_E/(1+n\sigma^2_\tau/\sigma^2)}>\frac{f_{\alpha, a-1, a(n-1)}}{(1+n\sigma^2_\tau/\sigma^2)}\right)$$

--

Hence,

$$1-\beta = P\left(F_{a-1, a(n-1)}>\frac{f_{\alpha, a-1, a(n-1)}}{(1+n\sigma^2_\tau/\sigma^2)}\right)$$

If we assume something about $\sigma_\tau^2/\sigma^2$, we can calculate the desired $n$, using the $F$ distribution function.

---

# Random-Effects Model - Example

When manufacturing food and drugs (medication) we usually aim for having a high degree of consistency, so that different batches produce the same product (quality, concentration, etc.). 

Consistency is not trivial to produce: production lines malfunction, shifts change, and machinery is sometimes replaced. 

The random effects model can be used to determine if consistency of the production lines should be rejected.

--

## The model - Olive oil acidity 

   * We are manufacturing olive oil, and each batch should have an acidity level of 0.5%
   
   * The factory wants to design an experiment which will test if the acidity is consistent.
   
   * Questions: What is our factor? What are the factor levels?
   
---

# Example - Olive oil acidity

The batch is our factor. It has many levels and therefore we treat it is a random effect.

--

$$\text{acidity} = \mu + \tau_\text{batch} + \epsilon_{batch,j}$$
.tiny[
```{r olive oil acidity example}

oil_manufacturing <- tibble(
   batch = factor(c("A", "A", "A", "A", "B", "B", "B", "B", "B", 
                    "C", "C", "C", "C", "D", "D", "E", "E")),
   acidity = 
      c(0.45, 0.49, 0.51, 0.50, 0.49, 0.60, 0.55, 0.41, 0.36, 
        0.50, 0.51, 0.49, 0.48, 0.50, 0.51, 0.08, 0.20))

oil_aov <- aov(formula = acidity ~ batch, data = oil_manufacturing)
summary(oil_aov)
TukeyHSD(oil_aov)
```
]

---

# Example - Olive Oil Acidity (cont.)

We can use Dunnett's test to specify the exact contrasts we would like to examine:

.small[
```{r olive oil multiple comparisons}
library(multcomp)
glht(oil_aov,
     linfct = mcp(batch = c("E-A=0", "E-B=0", "E-C=0", "E-D=0"))) %>% 
   summary()
```
]

---

# Randomized Complete Block Design

Sometimes we have an additional factor which is not the aim of the study. For example, imagine a clinical research where $a$ treatments are used in $b$ medical centers.

--

It might be that the fact that there are varying medical centers in itself influences the results.

--

If the selection of treatments is ranodmized across medical centers, the experiment is called a randomized complete block design.

--

|  | Blocks |  |  |  |  |  |
|------------|--------------------|--------------------|---------:|---------------------|------------------|-------------------|
| Treatments | 1 | 2 | $\ldots$ | $b$ | Totals | Averages |
| 1 | $y_{11}$ | $y_{12}$ | $\ldots$ | $y_{1b}$ | $y_{1\cdot}$ | $\bar{y}_{1\cdot}$ |
| $\vdots$ |  |  | $\vdots$ |  |  | $\vdots$ |
| $a$ | $y_{a1}$ | $y_{a2}$ | $\ldots$ | $y_{ab}$ | $y_{a\cdot}$ | $\bar{y}_{a\cdot}$ |
| Totals | $y_{\cdot1}$ | $y_{\cdot2}$ | $\ldots$ | $y_{\cdot b}$ | $y_{\cdot\cdot}$ |  |
| Averages | $\bar{y}_{\cdot1}$ | $\bar{y}_{\cdot2}$ | $\ldots$ | $\bar{y}_{\cdot b}$ |  |  |

---

# Randomized Complete Block Design (cont.)

The formula for this design is given by:

$$Y_{ij}=\mu + \tau_i + \beta_j + \epsilon_{ij}, \quad i\in\{1,\ldots,a\},j\in\{1,\ldots,b\}$$

Where

   * $\mu$ is the overall mean.
   
   * $\tau_i$ is the effect of the $i$th treatment.
   
   * $\beta_j$ is the effect of the $j$th block.
   
   * $\epsilon_{ij}$ is the error term $\epsilon_{ij}\sim\mathcal{N}(0,\sigma)$
   
--

We assume that the treatments and blocks are fixed factors, and that they are deviations from the overall mean, so $\sum_{i=1}^a{\tau_i}=0$ and $\sum_{j=1}^b{\beta_j}=0$. We test the hypothesis:

   * $H_0: \tau_1=\ldots=\tau_a=0$
   * $H_1: \exists i: \tau_i\neq0$

---

# Sum of Squares Identity in the Randomized Complete Block Design

The sum of squares identity can be broken into

$$\sum_{i=1}^a\sum_{j=1}^b(y_{ij}-\bar{y}_{\cdot\cdot})^2 = b\sum_{i=1}^a{(\bar{y}_{i\cdot}-\bar{y}_{\cdot\cdot})^2} + a\sum_{j=1}^b{(\bar{y}_{\cdot j}-\bar{y}_{\cdot\cdot})^2}+\sum_{i,j}{(y_{ij}-\bar{y}_{\cdot j} - \bar{y}_{i\cdot} + \bar{y}_{\cdot\cdot})^2}$$
--

Symbolically stated as

$$SS_T = SS_\text{Treatments} + SS_\text{Blocks} + SS_E$$

--

With degrees of freedom:

$$ab-1 = (a-1) + (b-1) + (a-1)(b-1)$$

---

# Randomized Complete Block Design Hypothesis Test

Set:

$$MS_\text{Treatments} = \frac{SS_\text{Treatments}}{a-1},\quad MS_\text{Blocks} = \frac{SS_\text{Blocks}}{b-1},\quad MS_E=\frac{SS_E}{(a-1)(b-1)}$$

--

The mean sum of squares is given by:

   * $E(MS_\text{Treatments}) = \sigma^2 + \frac{b\sum_{i=1}^a{\tau_i^2}}{a-1}$
   
   * $E(MS_\text{Blocks}) = \sigma^2 + \frac{a\sum_{j=1}^b{\beta_j^2}}{b-1}$
   
   * $E(MS_E) = \sigma^2$
   
--

If $H_0$ is true and all $\tau_i=0$ then:

$$F_0=\frac{MS_\text{Treatments}}{MS_E}$$

Is $F$-distributed with $a-1$ and $(a-1)(b-1)$ degrees of freedom.

---

# Example for Randomized Complete Block Design - ANOVA

An experiment was performed to determine the effect of four chemicals on the fabric strength (Example 13.5 from Montgomery).

.tiny[
```{r montgomery 13.5}
fabric_strength <- read_csv("https://raw.githubusercontent.com/adisarid/intro_statistics_R/master/lectures/data/montgomery_13.5_fabric_strength.csv", col_types = cols()) %>% 
   pivot_longer(cols = -chemical, names_to = "fabric_sample", values_to = "strength") %>% 
   mutate(chemical = factor(chemical))

fabric_aov <- aov(formula = strength ~ chemical + fabric_sample, data = fabric_strength)
summary(fabric_aov)
TukeyHSD(fabric_aov)
```
]