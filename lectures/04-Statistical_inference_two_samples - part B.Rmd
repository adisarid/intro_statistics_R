---
title: "Two sample variance tests, Independence"
subtitle: ""
author: "Adi Sarid"
institute: "Tel-Aviv University"
date: "updated: `r Sys.Date()`"
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
    css: xaringan-themer.css
---

```{r setup, include=FALSE}

library(xaringanthemer)

extra_css <- list(
   ".medium" = list("font-size" = "85%",
                    "code-font-size" = "85%"),
  ".small" = list("zoom" = "70%"),
  ".extra-small" = list("font-size" = "50%",
                        "code-font-size" = "50%"),
  ".tiny" = list("font-size" = "50%",
                 "code-font-size" = "50%",
                 "zoom" = "50%"),
  ".full-width" = list(
    display = "flex",
    width   = "100%",
    flex    = "1 1 auto"
  )
)

style_mono_accent(
   header_font_google = google_font("Open Sans"),
   text_font_google   = google_font("Rubik", "300", "300i"),
   code_font_google   = google_font("Fira Mono"),
   extra_css = extra_css,
   header_h1_font_size = "2.3rem"
   
)

theme_xaringan()

options(htmltools.dir.version = FALSE, fig.width = 3, fig.height = 3)
knitr::opts_chunk$set(fig.dim=c(3, 3), fig.align = "center")
library(tidyverse)
```

# Reminder from previous weeks

   * In the past month we discussed 
   
      * Hypothesis tests (mean, variance, goodness-of-fit)
      
      * Two sample tests for means (paired, unpaired)
   
   * We explored the Netflix data (of movies and TV shows)
   
      * E.g., We demonstrated hypothesis tests related to two sample comparison of movie duration

---

# Today

   * Comparing the variance of two samples (hypothesis test) השוואה בין שונויות

   * Checking for independence of two samples (contingency table) מבחן אי-תלות
   
   * Two sample proportion test
   
---

# Variance of two samples (F-test) השוואה בין שונויות

We talked about t-test when the variance is unknown and presented two cases (with equal variance and unequal variance). How would we decide which of the two to use? 

--

We would like to devise **a statistical test** to compare the variances of two samples. One method to compare two numbers is to divide them, i.e., $\sigma_1/\sigma_2$.

--

The $F$ distribution is the ratio of two independent chi-square random variables, divided by its degrees of freedom, i.e.:
   
$$F=\frac{W/u}{Y/v}$$

--

This test assumes that **both populations are normally distributed**.

--

The probability density function is given by the expression:

$$f(x)=\frac{\Gamma\left(\frac{u+v}{2}\right)\left(\frac{u}{v}\right)^{u/2}x^{(u/2)-1}}{\Gamma\left(\frac{u}{2}\right)\Gamma\left(\frac{v}{2}\right)\left[\left(\frac{u}{v}\right)x+1\right]^{(u+v)/2}}$$

---

# Illustration of the $F$ distribution
.small[
$$F=\frac{W/u}{Y/v}, \quad\mu=v/(v-2), \quad (\text{ for }v>2), \quad \sigma^2=\frac{2v^2(u+v-2)}{u(v-2)^2(v-4)}$$
]
.tiny[
```{r example F distribution, fig.dim=c(7,4)}
f_dist <- crossing(f = seq(0, 6, by = 0.1), df1 = c(1, 5, 10, 20), df2 = c(1, 5, 10, 20)) %>% 
   mutate(f_dense = pmap_dbl(.l = list(f, df1, df2), .f = df)) %>% 
   mutate(v = paste0("v=", df2),
          u = paste0("u=", df1)) %>% 
   mutate_at(vars(v,u), fct_inorder)

ggplot(f_dist, aes(x = f, y = f_dense)) + 
   geom_line() + 
   facet_grid(rows = vars(u), cols = vars(v)) + 
   theme_bw() + 
   guides(color = guide_legend("df"))

```
]

---

# Statistical hypothesis test for variance equality

Assuming two independent populations with normal distribution, then $F=\frac{S_1^2/\sigma_1^2}{S_2^2/\sigma_2^2}$ has an $F$ distribution with $u=n_1-1, v=n_2-1$ degrees of freedom.

Null hypothesis: $H_0: \sigma_1^2=\sigma_2^2$

Test statistic: $F_0 = \frac{S_1^2}{S_2^2}$

Alternative hypothesis (rejection criteria):

   * $H_1:\sigma_1^2\neq\sigma_2^2 \quad(f_0>f_{1-\alpha/2, n_1-1, n_2-1} \text{ or } f_0<f_{\alpha/2,n_1-1, n_2-1})$
   
   * $H_1:\sigma_1^2>\sigma_2^2 \quad(f_0>f_{1-\alpha,n_1-1, n_2-1})$
   
   * $H_1:\sigma_1^2<\sigma_2^2 \quad(f_0<f_{\alpha,n_1-1, n_2-1})$

---

# Example for F statistic variance test

.small[
```{r exercise variance between genders}
set.seed(0)
ipf <- read_csv("data/ipf_lifts.csv", col_types = cols()) %>% 
   filter(best3squat_kg > 0) %>% 
   sample_n(1000)
ipf %>% 
   group_by(sex) %>% 
   summarize_at(vars(contains("best3")), ~{(sd(., na.rm = T))^2})
```
]

It's pretty clear that males have a much higher variance, lets test this in an F test.

.small[
```{r test variance between genders}
var.test(formula = best3squat_kg ~ sex, data = ipf, ratio = 1, alternative = "less")
```
]

---

# Example for F statistic variance test

Another option:

.small[
```{r test variance option two}
male_squat <- ipf$best3squat_kg[ipf$sex == "M"]
female_squat <- ipf$best3squat_kg[ipf$sex == "F"]
var.test(x = female_squat, y = male_squat, data = ipf, ratio = 1, alternative = "less")
```
]

In this example we had

$$H_0: \sigma_1 = \sigma_2$$

$$H_1: \sigma_1 < \sigma_2$$

We reject the null hypothesis with $F_0=0.335$, and $p$-value $<0.05$.

--

Note that in the distribution tables, the F-statistic is provided for $\alpha=0.95$ so you might need to change the order of the numerator and denominator.

---

# Test for independence מבחן אי-תלות

   * Why are we interested in independence?
   
---

# Test for independence (contingency table)

When we have two variables and we want to examine independence between them, it is like comparing the contingencies (combinations) of the two variables, against the uniform distribution.

| Age | genderM | genderF | total |
|--------|---------|---------|--------|
| group1 | g1m | g1f | $n_{g1}$ |
| group2 | g2m | g2f | $n_{g2}$ |
| group3 | g3m | g3f | $n_{g3}$ |
| total | $n_M$ | $n_F$ | $n$ |

---

# Test for independence - intuition

   * The probability of being a male/female is 50%/50%.
   
   * The probability of being in each age group is 33%
   
   * The sample size is $n=492$

Under the null hypothesis of independence, what would this table look like?

.small[ 
| Age | genderM | genderF | total |
|--------|---------|---------|--------|
| group1 | g1m | g1f | $n_{g1}$ |
| group2 | g2m | g2f | $n_{g2}$ |
| group3 | g3m | g3f | $n_{g3}$ |
| total | $n_M$ | $n_F$ | $n$ |   
]

--

   * Each cell will have a sample of 82 observations (6 cells = 492).

--

   * The groups don't have to be equal according to the null hypothesis.
   
   * Let's assume that the sample is split: male/female 70/30, and the age groups 20/20/60. What would the table look like in this case, assuming independence of gender and age?

---

# Test for independence - hypothesis test

   * Now you know what is the Expected value in each cell. 
   
   * How do we compute the observed value? (e.g., using `count`)

   * The observed is the count within the cell, and the expected is the product of the marginal probabilities, i.e.:
   
      * The expected of Males in group2 under the null hypothesis is:  $E_{g2m}=(n_{g2}/n)\times(n_M/n)\times n$

   * This is the case when the variables are independent, i.e., $P(X=x,Y_y)=P(X=x)P(Y=y)$

--

This results in a $\chi^2$ test with $(r-1)(c-1)$ degrees of freedom.

--

$$\chi^2 = \sum_{i,j}\frac{(O_{i,j}-E_{i,j})^2}{E_{i,j}}$$

---

# Independence between variable via contingency table (example)
.small[
```{r contingency table independence test via chi square}
ipf_new <- ipf %>%
   filter(!is.na(age)) %>% 
   mutate(age_group = cut(age, breaks = c(0, 25, 35, 45, 55, 100))) %>% 
   count(age_group, sex) %>% 
   pivot_wider(id_cols = age_group, names_from = sex, values_from = n) %>% 
   select(2:3) %>% 
   as.matrix()
ipf_compare_res <- chisq.test(ipf_new)
ipf_compare_res
```
]

---

# Inference on two population proportions

We consider the case of two binomial parameters $p_1, p_2$. Let $X_1, X_2$ represent the number of successes in each sample. $\hat{P}_i=X_i/n_i$, have approximately normal distributions.

$$Z=\frac{\hat{P}_1-\hat{P}_2-(p_1-p_2)}{\sqrt{\frac{p_1(1-p_1)}{n_1} + \frac{p_2(1-p_2)}{n_2}}}$$
Is distributed approximately as $Z\sim\mathcal{N}(0,1)$.

--

Under the null hypothesis $H_0: p_1=p_2=p$ we have:

$$Z = \frac{\hat{P}_1-\hat{P}_2}{\sqrt{p(1-p)(1/n_1 + 1/n_2)}}$$

--

Where an estimator to $p$ is given by:

$$\hat{P}=\frac{X_1+X_2}{n_1+n_2}$$

---

# The test procedure for comparing two population proportions

Null hypothesis: $H_0: p_1=p_2$

Test statistic: $Z_0=\frac{\hat{P}_1-\hat{P}_2}{\sqrt{\hat{P}(1-\hat{P})(1/n_1 + 1/n_2)}}$

Alternative hypothesis (rejection criteria):

   * $H_1:p_1\neq p_2 \quad(z_0>z_{1-\alpha/2} \text{ or } z_0<z_{\alpha/2})$
   
   * $H_1:p_1>p_2 \quad (z_0>z_{1-\alpha})$
   
   * $H_1:p_1<p_2 \quad (z_0<z_{\alpha})$
   
---

# Proportion test using contingency table

There is another approach to proportion tests, combining what we learned about independence tests. E.g., consider the following sample: $n_1=100,n_2=700,v_1=10,v_2=30$ then $p_1=0.1,p_2=0.0428$.

Let's create a 2-by-2 contingency table:

.small[ 
| Group | Success | Failure | total | prop |
|-------|---------|---------|-------|------|
| 1     | 10      | 90      | 100   |12.5% |
| 2     | 30      | 670     | 700   |87.5% |
| total | 40      | 760     | 800   | -    |
| prop  | 5%      | 95%     | -     | -    |
]

.tiny[
```{r proprtion test via chisq}
prop.test(x = c(10, 30), n = c(100, 700), correct = FALSE)

observed_expected <- tribble(~observed, ~expected,
                             10, 10/40*10/100*800,
                             30, 30/40*30/700*800,
                             90, 90/760*90/100*800,
                             670, 670/760*670/700*800) %>% 
   mutate(chisq = (observed - expected)^2/expected)

1-pchisq(sum(observed_expected$chisq), df = 1)

```
]

---

# Short exercise of independence tests

Available here:

https://sarid.shinyapps.io/Independence_test

---

# Setting the sample sizes when comparing two population proportions

Very similar to what we've shown in the last lecture for one sample, but with a slightly different computation for the standard deviation under $H_1$. For example, in the two sided case we have:

$$\beta=\Phi\left[\frac{z_{1-\alpha/2}\sqrt{\bar{p}\bar{q}(1/n_1+1/n_2)}-(p_1-p_2)}{\sigma_{\hat{P}_1-\hat{P}_2}}\right]-\Phi\left[\frac{z_{\alpha/2}\sqrt{\bar{p}\bar{q}(1/n_1+1/n_2)}-(p_1-p_2)}{\sigma_{\hat{P}_1-\hat{P}_2}}\right]$$

--

With $\bar{p}=\frac{n_1p_1+n_2p_2}{n_1+n_2}, \bar{q}=\frac{n_1(1-p_1)+n_2(1-p_2)}{n_1+n_2}$ and

$$\sigma_{\hat{P}_1-\hat{P}_2}=\sqrt{\frac{p_1(1-p_1)}{n_1} + \frac{p_2(1-p_2)}{n_2}}$$

--

We can obtain the suggested sample (or power) using `pwr::pwr.2p.test` or `pwr::pwr2p2n.test`.

.small[
```{r demonstration for sample size using pwr}
pwr::pwr.2p2n.test(h = pwr::ES.h(p1 = 0.2, p2 = 0.3),
                   n1 = 150, n2 = NULL,
                   sig.level = 0.05,
                   power = 0.8,
                   alternative = "less")
```
]

---

# Effect Size גודל אפקט

We discussed p-value as the extent to which a statistical finding is significant. However, it is not the sole measure for the strength of a statistical finding.

--

In this context, see the ASA statement on $p$-Values [here](https://amstat.tandfonline.com/doi/full/10.1080/00031305.2016.1154108)

--

**Effect size** measures the magnitude of a phenomena. Effect size is a generic name for various measures such as:

   * $R^2$ in linear regression
   
   * $\rho$ Pearson correlation coefficient between two variables מקדם מתאם
   
   * Cohen's $d$ which relates to the difference between means (which we will now discuss)
   
   * Many more

---

# Effect Size - Cohen's $d$

The difference between two means divided by standard deviation, i.e.:

$$d=\frac{\bar{X}_1-\bar{X}_2}{S_p}$$

Where $S_p$ is the pooled standard deviation:

$$S_p=\sqrt{\frac{(n_1-1)S_1^2+(n_2-1)S_2^2}{n_1+n_2-2}}$$
.small[
```{r example for cohens d}
effsize::cohen.d(formula = best3squat_kg ~ sex, data = ipf)
```
]